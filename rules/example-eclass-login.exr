
########################################################################################################################################################
#
# Example library XX: Submitting forms (authenticating users) and handling redirects...
#                    
#                    
# 
# Related fields: XXXXX 
#
#
# TODO: Update next paragraph.
#
#
########################################################################################################################################################



{

# Description of the library

"libraryDescription": "Login to eclass and get get links from home page",



# List of rule names (or ruleReturnedValueNames as is the case in this example), whose extracted data should be stored in the csv file. 
# IMPORTANT: date the url was accessed (dateaccessed) and the url are always automatically added to the csv file

"csvLineFormat":[],

# The list of ruleNames (or ruleReturnedValueNames) that must return non-empty values
# to consider the extraction successful and the data be written to the csv file. 

"requiredFilledFields": [],

# Minimum percentage of ruleName that must return non-empty
# data during their application in order to consider the extraction process
# a success and hence add the extracted data to the csv file.

"allowedMinimumFilled" : 0.8


# How should the downloaded html page be rendered.
# WebScraper supports two modes of URL downloads:
# static: meaning that the web page does not load its content dynamically (via js or ajax) and one http request is enough to get
#         the entire page content. 
# dynamic: meaning the athe web page has dynamic content that is loaded via js or ajax once the web page has
#          been downloaded or is scrolled. Example of such dynamic pages are e.g. youtube pages where comments are only displayed
#          when the user scrolls down. Scraping such dynamic pages is also supported by WebScraper. Dynamic pages load slower though.
# 
# If renderPages has a value of False, this means the no page rendering is carried out and should be used only in case of pages that
# do not load content dynamicaly.
# If renderPages has a value of True, this means the page rendering is done and should be used only in case of pages that load content
# dynamically. 
# 
# Since we access wikipedia articles with no dynamic content, we will statically load these pages. Hence renderPages is set to False. This
# will make page loading faster. If renderPages is missing, it defaults to False.

"renderPages":True,

"ruleDynamicElements": [ 

                
		 {
		     "dpcURLActivationCondition" : "eclass\.upatras\.gr[/]{0,1}$",
		     "dpcType":"click",
		     "dpcPageElement":"a.btn",
		     "dpcScrolldown":-1,
		     "dpcWaitFor":"#inputEmail",
		     "dpcFillContent": ""
		 },
		 
		 {
		     "dpcURLActivationCondition" : "idp\.upnet\.gr/idp/profile.*execution=e1s1$",
		     "dpcType":"fill",
		     "dpcPageElement":"#inputEmail",
		     "dpcScrolldown":-1,
		     "dpcWaitFor":"",
		     "dpcFillContent": "eclass username"
		 },

		 {
		     "dpcURLActivationCondition" : "idp\.upnet\.gr/idp/profile.*execution=e1s1$",
		     "dpcType":"fill",
		     "dpcPageElement":"#inputPassword",		     
		     "dpcScrolldown":-1,
		     "dpcWaitFor":"",
		     "dpcFillContent": "eclass password"
		 },
		 
		 {
		     "dpcURLActivationCondition" : "idp\.upnet\.gr/idp/profile.*execution=e1s1$",
		     "dpcType":"click",
		     "dpcPageElement":"#loginButton",		     
		     "dpcScrolldown":-1,
		     "dpcWaitFor":"#dropdownMenu1",
		     "dpcIsSubmit": True,
		     "dpcRedirects": True
		     
		 }
		 
		 
 
],




######################################################################################
#
#  List of rules that will be applied on every downloaded page starts here
#
######################################################################################




# List of individual rules comprising this library and that will be applied to each page downloaded follows. 
# This library consists of one rule only, named getLinks. 

"library": [



# Rule to extract/scrape the title of the downloaded article. The title
# is assumed to be the teams name, not it's full name (or formal name)

{

 # If no ruleName is specified, the extracted data of this rule cannot be used
 # in  the csvLineFormat attribute.
 
 "ruleName": "getLinks",
 
 
 # Short description
 
 "ruleDescription": "Extracts links",
 
 
 
 # Regular expression specifying which URL pattern will trigger the
 # execution of this rule. 
 # This is a list ([]) meaning you may add many disjunctive regular expressions
 # Here we specify that this rule is to be activated when the URL contains en.wikipedia.org/wiki.
 # Special regular expression metacharacters (.) are escaped.
 
 "ruleURLActivationCondition": ["eclass\.upatras\.gr"],
 
 
 # A CSS selector specifying the element on the page to scrape.
 # NOTE: the CSS selector may return more than one mathing element.
 
 "ruleCSSSelector": "a[href]",
 
 
 
 # Once the CSS selector element in  ruleCSSSelector has been found, or data has been
 # extracted by ecRuleCSSSelector, what 
 # exactly to extract from this element: the text or some other attribute. 
 # text means simply return the text of the scraped element.
 #
 # In ruleMatchPreconditions, ruleTargetAttribute will be applied to the newly extracted
 # elements.
 
 "ruleTargetAttribute": "href",
 
 
 
 
 
 
 
 
 
 
 
 # Regular expression that specifies the condition the extracted text or attribute value has to
 # fulfill. Empty string here means no condition. If condition is not met, nothing is returned.
 "ruleContentCondition": "eclass\.upatras\.gr",
 
 # Does this rule return more than one result?
 "ruleReturnsMore": True,
 
 # If the rule returns more than one result, which result to return. Negative means all elements. 
 # This takes only effect if ruleReturnsMore is set to True.
 "ruleReturnedMatchPos": -1,
 
 # NOT YET SUPPORTED. How strict should the extraction be? If rule returns more than one result, should this be considered
 # an error?
 "ruleReturningMoreIsError": False,
 
 # List of characters to remove from the extracted value (text or attribute)
 "ruleRemoveChars": [],
}






]


}