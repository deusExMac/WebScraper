
########################################################################################################################################################
#
# Example library 5.1: Demonstrating the use of (post) match preconditions in rule getLinks to extract and follow links that meet more complicated
#                      conditions.
#                      
# 
# Related fields: ruleMatchPreconditions, getLinks, ecCSSSelector, ecTextCondition, ecRuleCSSSelector, ruleCSSSelector  
#
# TODO: Update/fix content below this line
#
# When to use match preconditions:
#      1) When you want to apply more checks to all the elements returned by ruleCSSSelector although this can also be
#         effected by carefullt authoring CSS selector for ruleCSSSelector.
#      2) When you want to extract subdata from each element based on value of the extracted data by ruleCSSSelector. You may for example
#         achieve behaviors like: for each result, get the value of the 3rd td only if the the 5th td matches a specific regular expression.
#
# The example rule below visits the URL https://en.wikipedia.org/wiki/List_of_European_Cup_and_UEFA_Champions_League_finals and
# extracts and follows only these links leading to football teams wikipedia pages, that have won the
# UEFA Champions League more than 3 time. These links are followed the team's name
# is extracted.
#
# More than one match preconditions can be defined in the context of the same rule. Currently, only operator ANY is supported for these match preconditions.
# If multiple match preconditions match, the first matching precondition's ecRuleCSSSelector is applied, if specified.
# 
# How to use this rule:
#
# crawl -n -1 -r rules/example5.1-en.wikipedia.exr -o csv/example5.1.csv  https://en.wikipedia.org/wiki/List_of_European_Cup_and_UEFA_Champions_League_finals
#
#
# 
# v0.1@11/09/2022
#
########################################################################################################################################################



{

# Description of the library

"libraryDescription": "Library to extract links leading to wikipedia pages of football clubs that have won UCL more than 3 times. The name of these clubs is extracted.",



# List of rule names, whose extracted data should be stored in the csv file. 
# IMPORTANT: date the url was accessed (dateaccessed) and the url are always automatically added to the csv file

"csvLineFormat":["teamName"],

# The list of ruleNames that must return non-empty values
# to consider the extraction successful and the data be written to the csv file. 

"requiredFilledFields": ["teamName"],

# Minimum percentage of ruleName that must return non-empty
# data during their application in order to consider the extraction process
# a success and hence add the extracted data to the csv file.

"allowedMinimumFilled" : 0.8


# How should the downloaded html page be rendered.
# WebScraper supports two modes of URL downloads:
# static: meaning that the web page does not load its content dynamically (via js or ajax) and one http request is enough to get
#         the entire page content. 
# dynamic: meaning the athe web page has dynamic content that is loaded via js or ajax once the web page has
#          been downloaded or is scrolled. Example of such dynamic pages are e.g. youtube pages where comments are only displayed
#          when the user scrolls down. Scraping such dynamic pages is also supported by WebScraper. Dynamic pages load slower though.
# 
# If renderPages has a value of False, this means the no page rendering is carried out and should be used only in case of pages that
# do not load content dynamicaly.
# If renderPages has a value of True, this means the page rendering is done and should be used only in case of pages that load content
# dynamically. 
# 
# Since we access wikipedia articles with no dynamic content, we will statically load these pages. Hence renderPages is set to False. This
# will make page loading faster. If renderPages is missing, it defaults to False.

"renderPages":False,



# List of individual rules comprising this library and that will be applied to each page downloaded follows. 
# This library consists of two rules, named teamName and getLinks. 

"library": [



# Rule to extract/scrape the title of the downloaded article. The title
# is assumed to be the teams name, not it's full name (or formal name)

{

 # If no ruleName is specified, the extracted data of this rule cannot be used
 # in  the csvLineFormat attribute.
 
 "ruleName": "teamName",
 
 
 # Short description
 
 "ruleDescription": "Extracts the team name",
 
 
 
 # Regular expression specifying which URL pattern will trigger the
 # execution of this rule. 
 # This is a list ([]) meaning you may add many disjunctive regular expressions
 # Here we specify that this rule is to be activated when the URL contains en.wikipedia.org/wiki.
 # Special regular expression metacharacters (.) are escaped.
 
 "ruleURLActivationCondition": ["en\.wikipedia\.org/wiki"],
 
 
 # A CSS selector specifying the element on the page to scrape.
 # NOTE: the CSS selector may return more than one mathing element.
 
 "ruleCSSSelector": "#firstHeading",
 
 

 
 
 # Once the CSS selector element in  ruleCSSSelector has been found, or data has been
 # extracted by ecRuleCSSSelector, what 
 # exactly to extract from this element: the text or some other attribute. 
 # text means simply return the text of the scraped element.
 #
 # If more than one value is returned, this attribute is applied to each and every returned element. 
 
 "ruleTargetAttribute": "text",
 
 # Regular expression that specifies the condition the extracted text or attribute value has to
 # fulfill. Empty string here means no condition. If condition is not met, nothing is returned.
 "ruleContentCondition": "",
 
 # Does this rule return more than one result?
 "ruleReturnsMore": False,
 
 # If the rule returns more than one result, which result to return. Negative means all elements. 
 # This takes only effect if ruleReturnsMore is set to True.
 "ruleReturnedMatchPos": -1,
 
 # NOT YET SUPPORTED. How strict should the extraction be? If rule returns more than one result, should this be considered
 # an error?
 "ruleReturningMoreIsError": False,
 
 # List of characters to remove from the extracted value (text or attribute)
 "ruleRemoveChars": [],
}, 







{

 # Name of rule. Remember getLinks is a reserved word implying
 # a very specific behavior.
 "ruleName": "getLinks",
 
 "ruleDescription": "Extracting hyperlinks from the downloaded webpage. This rule extracts only links to teams that have won the UCL more than 3 times.",
 
 # Regular expression specifying for which URLs/pages to activate this rule.
 "ruleURLActivationCondition": ["en\.wikipedia\.org.*$"],
 
 # CSS selector containing the information (hyperlink) to extract.
 # This selector will return all table rows of the table with heading
 # "Performances in the European Cup and UEFA Champions League by club."
 # That table contains, in each row (tr): the times the club have won UCL as well 
 # a link to the clubs name.
 
 "ruleCSSSelector": "h3 + .plainrowheaders tr",
 
 
 "ruleMatchPreconditions": [
   
                                 # A match precondition. This precondition checks if each
                                 # row extracted by ruleCSSSelector has in the second td element
                                 # a number greater than 3. If so, the th element from the 
                                 # processed row is extracted and returned as the result.
                                 # This is done for all tr elements.
                                 {
                                   # Element of tr to check. This CSS selector is applied to
                                   # each and every tr element  
                                   # returned by ruleCSSSelector.
                                   
                                   "ecCSSSelector" : "td:nth-child(2)", 
                                   
                                   
                                   # Condition the elements specified by ecCSSSelector have to match. 
                                   # tr elements that do not match this condition will be
                                   # removed from the extracted list.
                                   # Here we check if td element td:nth-child(2), that keeps the number of titles, 
                                   # contains a number that is greater than 3 (>3).
                                   
                                   "ecTextCondition" : "([4-9]|\d{2,})",
                                   
                                   
                                   # If a match, i.e. number is > 3, return the link leading to
                                   # the team's wikipedia page. This link is the second 
                                   # a element in the table heading (th) inside the table row
                                   # (tr) currently being processed. The first a element
                                   # being a link to the teams football federation it belongs.
                                   # Anchor is the flag. (11/09/2022)
                                   #
                                   # NOTE: this will result in returning a new element. On this new element 
                                   # the data specified in ruleTargetAttribute will be returned. This will result 
                                   # in a list of string values associated with the key with name ruleName.
                                                                     
                                   "ecRuleCSSSelector" : "th a[href]:nth-child(2)"
                                 }
     
                             ],
 
 
 
 
 
 
 # From the specified selector, we are interested only in the value of the
 # attribute href, which contains the hyperlink.
 # NOTICE: WebScraper takes care of relative links
 "ruleTargetAttribute": "href",
 
 # Once we got the value of the target attribute, this regular expression
 # specifies a condition that the value has to meet. Here, we are interested 
 # only in hyperlinks that point to english wikipedia pages. I.e. pages outside
 # of the english wikipedia site will not be extracted and hence won't be followed.
 "ruleContentCondition": "en\.wikipedia\.org/.*$",
 
 # This signifies that this rule will not return only one chunk of information, but
 # a list of chunkc since a web page may have many <a href= > tags.
 "ruleReturnsMore": True,
 
 # -1 means return all matched
 "ruleReturnedMatchPos": -1,
 
 "ruleReturningMoreIsError": False 
}





] # library


}