[Default]

outputDir = ./articles

; maximum number of articles to download
; set to -1 for unlimited
maxArticles = 12

; Should we download also the content of
; articles?
contentDownload = true


; Store documents in a csv file? If so, how?
csvSave = true
csvFileName = allArticles.csv
csvSeparator = ;

[Shell]
commandPrompt = Scrapper >>



[Rules]

; File containing metadata for 
; extraction rules from pages
ruleFile = ./lib.conf

[Crawler]

; Sleep time between consecutive http requests
; In seconds
sleepTime = 3.6